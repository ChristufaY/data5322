{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "862658de",
   "metadata": {},
   "source": [
    "## Import statements and loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2defa97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, SeparableConv2D, SpatialDropout2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c5f371",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('bird_spectrograms.hdf5', 'r')\n",
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871136d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in list(f.keys()):\n",
    "    print(f[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abaab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seeds to ensure reproducibility \n",
    "np.random.seed(5322)\n",
    "tf.random.set_seed(5322)\n",
    "random.seed(5322)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdaa056",
   "metadata": {},
   "source": [
    "## Multiclass Classification (All species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96aaac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "# loop through each species' data\n",
    "for species in list(f.keys()):\n",
    "    spectrograms = np.array(f[species])  # (128, 517, N)\n",
    "    n_samples = spectrograms.shape[2]\n",
    "    labels = [species] * n_samples\n",
    "\n",
    "    X_list.append(spectrograms)\n",
    "    y_list.extend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d7a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack and reshape\n",
    "X = np.concatenate(X_list, axis = 2)      # (128, 517, total_samples)\n",
    "X = np.transpose(X, (2, 0, 1))           # (samples, 128, 517)\n",
    "X = X[..., np.newaxis]                   # (samples, 128, 517, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b4535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize spectrograms to [0, 1]\n",
    "X = X / np.max(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f768e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels to arrays\n",
    "y = np.array(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945487ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode species to ints\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)          # e.g., 'amecro' → 0, 'amerob' → 1, etc.\n",
    "label_map = dict(zip(le.transform(le.classes_), le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7869118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode\n",
    "y_onehot = to_categorical(y_encoded)     # shape: (samples, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a3c838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test. stratify to balance species\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_onehot, test_size = 0.2, random_state = 5322, stratify = y_encoded\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0f44b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also get y_test_raw = y_encoded to decode predictions later and for plotting\n",
    "_, y_test_raw = train_test_split(\n",
    "    y_encoded, test_size = 0.2, random_state = 5322, stratify = y_encoded\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3452ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tried data augmentation by shifting, zooming, and filling. rotating did not make sense so did not do that\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ed05a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(le.classes_)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f59c456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first multiclass model\n",
    "model = Sequential([\n",
    "    # layer group 1\n",
    "    Conv2D(32, (3, 3), activation = 'relu', input_shape = (128, 517, 1), kernel_regularizer = l2(0.0001), padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    SpatialDropout2D(0.3),\n",
    "    # group 2\n",
    "    Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer = l2(0.0001), padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    SpatialDropout2D(0.3),\n",
    "    # group 3\n",
    "    SeparableConv2D(128, (3, 3), activation = 'relu', kernel_regularizer = l2(0.0001), padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.4),\n",
    "    # group 4\n",
    "    SeparableConv2D(128, (3, 3), activation = 'relu', kernel_regularizer = l2(0.0001), padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.4),\n",
    "    # group 5\n",
    "    SeparableConv2D(256, (3, 3), activation = 'relu', kernel_regularizer = l2(0.0001), padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.5),\n",
    "    # global pooling\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(units = 128, activation = 'relu', kernel_regularizer = l2(0.0001)),\n",
    "    Dropout(0.5),\n",
    "    Dense(units = num_classes, activation = 'softmax')\n",
    "], name = \"Multiclass_Model_1\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer = Adam(learning_rate = 0.0001),\n",
    "    loss = CategoricalCrossentropy(),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True)\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size = 16),\n",
    "    validation_data = (X_test, y_test),\n",
    "    epochs = 100,\n",
    "    # batch_size = 16,\n",
    "    # validation_split = 0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'\\nTest accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803dd151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# get class labels in correct order (by integer encoding)\n",
    "target_names = [label_map[i] for i in sorted(label_map.keys())]\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names = target_names, digits = 4, zero_division = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123f1934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize = (10, 8))\n",
    "sns.heatmap(cm, annot = True, fmt = 'd', cmap = 'Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75caf9d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4615b15c",
   "metadata": {},
   "source": [
    "## Multiclass Classification with adjustments\n",
    "- added label smoothing of 0.05\n",
    "- increased batch size to 64 from 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8082b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first multiclass model\n",
    "model = Sequential([\n",
    "    # layer group 1\n",
    "    Conv2D(32, (3, 3), activation = 'relu', input_shape = (128, 517, 1), kernel_regularizer = l2(0.0001), padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.2),\n",
    "    # group 2\n",
    "    Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer = l2(0.0001), padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.2),\n",
    "    # group 3\n",
    "    Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer = l2(0.0001), padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.3),\n",
    "    # group 4\n",
    "    Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer = l2(0.0001), padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.3),\n",
    "    # group 5\n",
    "    Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer = l2(0.0001), padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.4),\n",
    "    # global pooling\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(units = 256, activation = 'relu', kernel_regularizer = l2(0.0001)),\n",
    "    Dropout(0.3),\n",
    "    Dense(units = 128, activation = 'relu', kernel_regularizer = l2(0.0001)),\n",
    "    Dropout(0.4),\n",
    "    Dense(units = num_classes, activation = 'softmax')\n",
    "], name = \"Multiclass_Model_2\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer = Adam(learning_rate = 0.0001),\n",
    "    loss = CategoricalCrossentropy(label_smoothing = 0.05),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs = 100,\n",
    "    batch_size = 64,\n",
    "    validation_split = 0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'\\nTest accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4ee757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first multiclass model\n",
    "model = Sequential([\n",
    "    # layer group 1\n",
    "    Conv2D(32, (3, 3), activation = 'relu', input_shape = (128, 517, 1), kernel_regularizer = l2(0.0001), padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.2),\n",
    "    # group 2\n",
    "    Conv2D(64, (3, 3), activation = 'relu', kernel_regularizer = l2(0.0001), padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.2),\n",
    "    # group 3\n",
    "    Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer = l2(0.0001), padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.3),\n",
    "    # group 4\n",
    "    Conv2D(128, (3, 3), activation = 'relu', kernel_regularizer = l2(0.0001), padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.3),\n",
    "    # group 5\n",
    "    Conv2D(256, (3, 3), activation = 'relu', kernel_regularizer = l2(0.0001), padding = 'same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.4),\n",
    "    # global pooling\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(units = 256, activation = 'relu', kernel_regularizer = l2(0.0001)),\n",
    "    Dropout(0.3),\n",
    "    Dense(units = 128, activation = 'relu', kernel_regularizer = l2(0.0001)),\n",
    "    Dropout(0.4),\n",
    "    Dense(units = num_classes, activation = 'softmax')\n",
    "], name = \"Multiclass_Model_1\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer = Adam(learning_rate = 0.0001),\n",
    "    loss = CategoricalCrossentropy(label_smoothing = 0.05),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs = 100,\n",
    "    batch_size = 16,\n",
    "    validation_split = 0.2,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'\\nTest accuracy: {test_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
